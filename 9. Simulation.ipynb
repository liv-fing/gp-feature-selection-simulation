{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "Testing and comparison of the performance of various methods of Gaussian process feature selection for sparse datasets. \n",
    "\n",
    "**Models:**\n",
    "\n",
    "1. Standard optimization\n",
    "\n",
    "2. ARD kernel optimization\n",
    "\n",
    "3. Lasso feature selection before optimization\n",
    "    - $\\lambda$ selected via cross-validation\n",
    "4. Lasso feature selection before ARD kernel optimization\n",
    "    - $\\lambda$ selected via cross-validation\n",
    "5. L1-penalized optimization\n",
    "    - $\\lambda$ selected via cross-validation\n",
    "    - Includes added thresholding\n",
    "\n",
    "\n",
    "**Metrics:**\n",
    "\n",
    "Three metrics will be used to compare the performance of the 5 models. \n",
    "\n",
    "- Estimation error of coefficients $$\\varepsilon_{\\beta} = \\|\\beta - \\hat{\\beta}\\|_2$$\n",
    "- Prediction error $$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i - \\hat{y_i}\\right)^2}$$\n",
    "- Computation Time:\n",
    "    - Total runtime for model fitting, training, and prediction, measured in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow as gpf\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoLarsCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPFeatureSelect:\n",
    "\n",
    "    def __init__(self, model_type = 'std', cv = 5):\n",
    "        self.model_type = model_type\n",
    "        self.cv = cv\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaledX = None\n",
    "        self.selected_features = None\n",
    "        self.lasso_model = None\n",
    "        self.lambda_val = None\n",
    "        self.beta_hat = None\n",
    "        self.runtime = None\n",
    "        self.opt = gpf.optimizers.Scipy()\n",
    "        \n",
    "    def training_loss_lasso(self):\n",
    "        base_loss = self.gp_model.training_loss()\n",
    "        l1_penalty = self.lambda_val * tf.reduce_sum(tf.abs(self.gp_model.mean_function.A))\n",
    "        total_loss = base_loss + l1_penalty\n",
    "        return total_loss\n",
    "\n",
    "    def cv_lasso_lars(self, X, y):\n",
    "        if self.model_type in ['lasso_std', 'lasso_ard']:\n",
    "            las = LassoLarsCV(cv = self.cv)\n",
    "            las.fit(X, y.ravel())\n",
    "            mask = np.abs(las.coef_) > 1e-4\n",
    "            self.selected_features = np.where(mask)[0]\n",
    "            self.beta_hat = las.coef_\n",
    "            self.lasso_model = las\n",
    "            self.lambda_val = las.alpha_\n",
    "            return X[:, self.selected_features]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"cv_lasso_lars called on non-lasso model\")\n",
    "\n",
    "    def tune_lambda(self, X, y):\n",
    "        def run_cv(lambda_grid):\n",
    "            best_lbda = None\n",
    "            best_rmse = np.inf\n",
    "            lambda_rmse_pairs = []\n",
    "\n",
    "            for l in lambda_grid:\n",
    "                rmses = []\n",
    "                kf = KFold(n_splits=self.cv, shuffle=True, random_state=22)\n",
    "                for train_index, val_index in kf.split(X):\n",
    "                    X_train, X_val = X[train_index], X[val_index]\n",
    "                    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "                    self.init_ard_gp_mod(X_train, y_train)\n",
    "                    self.lambda_val = l\n",
    "                    self.opt.minimize(\n",
    "                        lambda: self.training_loss_lasso(),\n",
    "                        self.gp_model.trainable_variables\n",
    "                    )\n",
    "\n",
    "                    y_pred = self.gp_model.predict_f(X_val)[0].numpy().flatten()\n",
    "                    rmse = np.sqrt(np.mean((y_val - y_pred) ** 2))\n",
    "                    rmses.append(rmse)\n",
    "\n",
    "                avg_rmse = np.mean(rmses)\n",
    "                lambda_rmse_pairs.append((l, avg_rmse))\n",
    "\n",
    "                #print('\\nRMSE for this fold: ', avg_rmse)\n",
    "\n",
    "                if avg_rmse < best_rmse:\n",
    "                    best_rmse = avg_rmse\n",
    "                    best_lbda = l\n",
    "\n",
    "            return best_lbda, lambda_rmse_pairs\n",
    "\n",
    "        coarse_grid = np.logspace(-1, 1, 10)\n",
    "        #print(\"Coarse grid:\", coarse_grid)\n",
    "\n",
    "        best_coarse, coarse_log = run_cv(coarse_grid)\n",
    "        #print(\"Best coarse Î»:\", best_coarse)\n",
    "        return best_coarse\n",
    "\n",
    "        # fine_grid = np.linspace(best_coarse * 0.5, best_coarse * 1.5, 10)\n",
    "        # best_fine, fine_log = run_cv(fine_grid)\n",
    "        # self.lambda_val = best_fine\n",
    "        # self.lambda_rmse_log = coarse_log + fine_log\n",
    "        #return best_fine\n",
    "\n",
    "        \n",
    "    def init_gp_mod(self, X, y):\n",
    "        y = np.asarray(y).reshape(-1, 1)\n",
    "        m = X.shape[1]\n",
    "        A_init = tf.zeros((m, 1), dtype=tf.float64)\n",
    "        b_init = tf.zeros((1,), dtype=tf.float64)\n",
    "\n",
    "        kernel = gpf.kernels.SquaredExponential(lengthscales=1)\n",
    "        likelihood = gpf.likelihoods.Gaussian()\n",
    "        mean_function = gpf.mean_functions.Linear(A=A_init, b = b_init) \n",
    "\n",
    "        self.gp_model = gpf.models.GPR(data = (X, y.reshape(-1,1)), kernel = kernel, likelihood = likelihood, mean_function = mean_function)\n",
    "\n",
    "    def init_ard_gp_mod(self, X, y):\n",
    "        y = np.asarray(y).reshape(-1, 1)\n",
    "        m = X.shape[1]\n",
    "        A_init = tf.zeros((m, 1), dtype=tf.float64)\n",
    "        b_init = tf.zeros((1,), dtype=tf.float64)\n",
    "\n",
    "        kernel = gpf.kernels.SquaredExponential(lengthscales=np.ones(m))\n",
    "        likelihood = gpf.likelihoods.Gaussian()\n",
    "        mean_function = gpf.mean_functions.Linear(A=A_init, b = b_init) \n",
    "\n",
    "        self.gp_model = gpf.models.GPR(data = (X, y.reshape(-1,1)), kernel = kernel, likelihood = likelihood, mean_function = mean_function)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #start_time = time.time()\n",
    "\n",
    "        X = self.scaler.fit_transform(X)\n",
    "        y = np.asarray(y).reshape(-1,1)\n",
    "\n",
    "        if self.model_type == 'std':\n",
    "            self.init_gp_mod(X, y)\n",
    "            self.opt.minimize(\n",
    "                self.gp_model.training_loss,\n",
    "                self.gp_model.trainable_variables)\n",
    "            self.beta_hat = self.gp_model.mean_function.A.numpy().flatten()\n",
    "\n",
    "        elif self.model_type =='ard':\n",
    "            self.init_ard_gp_mod(X, y)\n",
    "            self.opt.minimize(\n",
    "                self.gp_model.training_loss,\n",
    "                self.gp_model.trainable_variables)\n",
    "            self.beta_hat = self.gp_model.mean_function.A.numpy().flatten()\n",
    "\n",
    "        elif self.model_type =='lasso_std':\n",
    "            reducedX = self.cv_lasso_lars(X,y)\n",
    "            self.init_gp_mod(reducedX, y)\n",
    "            self.opt.minimize(\n",
    "                self.gp_model.training_loss,\n",
    "                self.gp_model.trainable_variables)\n",
    "            self.beta_hat = self.gp_model.mean_function.A.numpy().flatten()\n",
    "            \n",
    "        elif self.model_type == 'lasso_ard':\n",
    "            reducedX = self.cv_lasso_lars(X,y)\n",
    "            self.init_ard_gp_mod(reducedX, y)\n",
    "            self.opt.minimize(\n",
    "                self.gp_model.training_loss,\n",
    "                self.gp_model.trainable_variables)\n",
    "            self.beta_hat = self.gp_model.mean_function.A.numpy().flatten()\n",
    "\n",
    "        elif self.model_type == 'l1_gp': \n",
    "            if self.lambda_val is None:\n",
    "                self.tune_lambda(X,y)\n",
    "\n",
    "            # start by training on all features\n",
    "            self.init_ard_gp_mod(X, y)\n",
    "            self.opt.minimize(\n",
    "                lambda: self.training_loss_lasso(),\n",
    "                self.gp_model.trainable_variables   \n",
    "            )\n",
    "\n",
    "            # threshold coefficients to select features\n",
    "            beta_full = self.gp_model.mean_function.A.numpy().flatten()\n",
    "            threshold = 1e-4  ###\n",
    "            mask = np.abs(beta_full) > threshold\n",
    "\n",
    "            self.beta_hat = beta_full\n",
    "            self.selected_features = np.where(mask)[0]\n",
    "\n",
    "            if len(self.selected_features) == 0:\n",
    "                print ('No features selected after thresholding')\n",
    "                return\n",
    "            \n",
    "            # retrain on selected features\n",
    "            X_reduced = X[:, self.selected_features]\n",
    "            self.init_ard_gp_mod(X_reduced, y)\n",
    "            self.opt.minimize(\n",
    "                lambda: self.training_loss_lasso(),\n",
    "                self.gp_model.trainable_variables)\n",
    "            \n",
    "            # update beta_hat \n",
    "            self.beta_hat = self.gp_model.mean_function.A.numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = self.scaler.transform(X)\n",
    "        if self.selected_features is not None:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.iloc[:, self.selected_features]\n",
    "            else:\n",
    "                X = X[:, self.selected_features]\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        mean, _ = self.gp_model.predict_f(X)\n",
    "        return mean.numpy().flatten()\n",
    "    \n",
    "    def get_metrics(self, Xtest, ytest, beta_true=None):\n",
    "        y_pred = self.predict(Xtest)\n",
    "        rmse = np.sqrt(np.mean((ytest - y_pred) ** 2))\n",
    "        beta_error = None\n",
    "        if beta_true is not None and self.beta_hat is not None:\n",
    "            if self.selected_features is not None:\n",
    "                beta_error = np.linalg.norm(beta_true[self.selected_features] - self.beta_hat)\n",
    "            else:\n",
    "                beta_error = np.linalg.norm(beta_true - self.beta_hat)\n",
    "        return {\n",
    "            'rmse': rmse,\n",
    "            'beta_error': beta_error,\n",
    "            'runtime': self.runtime\n",
    "        }\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each model using one simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Simulation Datasets/N1000_AP10_seed30/N1000_AP10_seed30_data.csv'\n",
    "meta_path = 'Simulation Datasets/N1000_AP10_seed30/N1000_AP10_seed30_meta.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path, 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "beta_true = np.array(meta['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(data_path)\n",
    "dat.head()\n",
    "X = dat.drop(columns = 'y')\n",
    "y = dat['y']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.4678241977454105, 'beta_error': 0.409910811454901, 'runtime': None}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_std = GPFeatureSelect(model_type='std')\n",
    "mod1_std.fit(Xtrain,ytrain)\n",
    "mod1_std.get_metrics(Xtest, ytest, beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.4678242974598465,\n",
       " 'beta_error': 0.40991058419664683,\n",
       " 'runtime': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2_ard = GPFeatureSelect(model_type = 'ard')\n",
    "mod2_ard.fit(Xtrain, ytrain)\n",
    "mod2_ard.get_metrics(Xtest, ytest, beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.4654936328474515,\n",
       " 'beta_error': 0.37214117231477783,\n",
       " 'runtime': None}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3_las_std = GPFeatureSelect(model_type = 'lasso_std')\n",
    "mod3_las_std.fit(Xtrain, ytrain)\n",
    "mod3_las_std.get_metrics(Xtest, ytest, beta_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06848557179489526\n"
     ]
    }
   ],
   "source": [
    "print(mod3_las_std.lambda_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.4457837577451293,\n",
       " 'beta_error': 0.24527972598151362,\n",
       " 'runtime': None}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod4_las_ard = GPFeatureSelect(model_type = 'lasso_ard')\n",
    "mod4_las_ard.fit(Xtrain, ytrain)\n",
    "mod4_las_ard.get_metrics(Xtest, ytest, beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06848557179489526\n"
     ]
    }
   ],
   "source": [
    "print(mod4_las_ard.lambda_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.4676104270122006, 'beta_error': 0.3783292548381168, 'runtime': None}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod5_l1_gp = GPFeatureSelect(model_type = 'l1_gp')\n",
    "mod5_l1_gp.fit(Xtrain, ytrain)\n",
    "mod5_l1_gp.get_metrics(Xtest, ytest, beta_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print(mod5_l1_gp.lambda_val) # ask about this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
