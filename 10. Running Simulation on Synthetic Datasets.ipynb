{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Running Simulation on Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from gp_feature_select import GPFeatureSelect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing GPFeatureSelect with a simple dataset\n",
    "\n",
    "Xtrain = pd.read_csv('Simulation Datasets/N11000_AP10_noise0.1_seed0/Size500/Rep1.csv').drop(columns='y') \n",
    "ytrain = pd.read_csv('Simulation Datasets/N11000_AP10_noise0.1_seed0/Size500/Rep1.csv')['y']\n",
    "\n",
    "mod = GPFeatureSelect(model_type = 'lasso_ard')\n",
    "mod.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_synthetic(unique_name, size, num_rep, model_type, seed):\n",
    "\n",
    "    meta_path = f'Simulation Datasets/{unique_name}/{unique_name}_meta.json'\n",
    "    test_path = f'Simulation Datasets/{unique_name}/{unique_name}_test.csv'\n",
    "\n",
    "    data_path = f'Simulation Datasets/{unique_name}/Size{size}/Rep{num_rep}.csv' \n",
    "\n",
    "    results_path = f'Simulation Datasets/{unique_name}/Size{size}/Rep{num_rep}_{model_type}results.json'\n",
    "\n",
    "    if os.path.exists(results_path):\n",
    "        print(f\"Results file {results_path} already exists, skipping computation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {unique_name}, Size: {size}, Rep: {num_rep}, Model: {model_type}, Seed: {seed}\")\n",
    "\n",
    "    X = pd.read_csv(data_path).drop(columns='y') \n",
    "    y = pd.read_csv(data_path)['y']\n",
    "\n",
    "    Xtest = pd.read_csv(test_path).drop(columns='y')\n",
    "    ytest = pd.read_csv(test_path)['y']\n",
    "\n",
    "    # open meta data and true beta values\n",
    "    with open(meta_path, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    beta_true = np.array(meta['beta'])\n",
    "                \n",
    "\n",
    "\n",
    "    mod = GPFeatureSelect(model_type=model_type)\n",
    "    print('Fitting model')\n",
    "    mod.fit(X, y)\n",
    "    print('Getting metrics')\n",
    "    results = mod.get_metrics(X, y, Xtest, ytest, beta_true=beta_true)\n",
    "\n",
    "    for k, v in results.items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            results[k] = v.tolist()\n",
    "    print('Saving results')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "def extract_seed(unique_name):\n",
    "    seed_str = unique_name.split('_')[-1]\n",
    "    return int(seed_str.replace('seed', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Seed from N11000_AP20_noise1.0_seed5: 5\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'Simulation Datasets'\n",
    "unique_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "print(f'Extracting Seed from {unique_names[0]}: {extract_seed(unique_names[0])}')\n",
    "\n",
    "model_types = ['l1_gp'] #['std', 'ard', 'lasso_std', 'lasso_ard', 'l1_gp']\n",
    "\n",
    "sizes = [1000] # can also do 50 or 2000\n",
    "num_reps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file Simulation Datasets/N11000_AP10_noise0.5_seed1/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 1, Model: l1_gp, Seed: 7\n",
      "Results file Simulation Datasets/N11000_AP10_noise0.1_seed0/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n",
      "Results file Simulation Datasets/N11000_AP20_noise0.1_seed3/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:  1.2min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:  1.2min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  1.2min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Results file Simulation Datasets/N11000_AP20_noise0.5_seed4/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n",
      "Results file Simulation Datasets/N11000_AP10_noise1.0_seed2/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n",
      "Results file Simulation Datasets/N11000_AP20_noise1.0_seed5/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:  1.2min remaining:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  1.2min remaining:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:  1.2min remaining:   20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file Simulation Datasets/N11000_AP50_noise1.0_seed8/Size1000/Rep1_l1_gpresults.json already exists, skipping computation.\n",
      "Processing N11000_AP50_noise0.1_seed6, Size: 1000, Rep: 1, Model: l1_gp, Seed: 6\n",
      "Fitting model\n",
      "Getting metrics\n",
      "Saving results\n",
      "Getting metrics\n",
      "Saving results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 203.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 203.9min finished\n"
     ]
    }
   ],
   "source": [
    "sim_synthetic = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_one_synthetic)(unique_name, size, num_rep, model_type, extract_seed(unique_name)) \n",
    "    for unique_name in unique_names\n",
    "    for size in sizes\n",
    "    for num_rep in range(1, num_reps + 1)\n",
    "    for model_type in model_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
