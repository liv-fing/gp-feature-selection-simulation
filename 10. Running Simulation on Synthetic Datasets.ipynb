{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Running Simulation on Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from gp_feature_select import GPFeatureSelect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_synthetic(unique_name, model_type, seed):\n",
    "\n",
    "    data_path = f'Simulation Datasets/{unique_name}/{unique_name}_data.csv'\n",
    "    meta_path = f'Simulation Datasets/{unique_name}/{unique_name}_meta.json'\n",
    "\n",
    "    data = pd.read_csv(data_path)   \n",
    "    X = data.drop(columns = 'y')\n",
    "    y = data['y']\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # open meta data and true beta values\n",
    "    with open(meta_path, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    beta_true = np.array(meta['beta'])\n",
    "                \n",
    "\n",
    "    mod = GPFeatureSelect(model_type=model_type)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    results = mod.get_metrics(Xtrain, ytrain, Xtest, ytest, beta_true=beta_true)\n",
    "\n",
    "    for k, v in results.items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            results[k] = v.tolist()\n",
    "\n",
    "    # store results in a file in the proper folder\n",
    "    results_path = f'Simulation Datasets/{unique_name}/{unique_name}_{model_type}results.json'\n",
    "\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "def extract_seed(unique_name):\n",
    "    seed_str = unique_name.split('_')[-1]\n",
    "    return int(seed_str.replace('seed', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Seed from N100_AP50_noise1.0_seed44: 44\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'Simulation Datasets'\n",
    "unique_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "print(f'Extracting Seed from {unique_names[0]}: {extract_seed(unique_names[0])}')\n",
    "\n",
    "model_types = ['std', 'ard', 'lasso_std', 'lasso_ard', 'l1_gp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 318 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 345 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed: 80.6min\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed: 90.5min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed: 107.2min\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed: 127.0min\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed: 150.3min\n",
      "[Parallel(n_jobs=-1)]: Done 525 tasks      | elapsed: 168.8min\n",
      "[Parallel(n_jobs=-1)]: Done 558 tasks      | elapsed: 181.3min\n",
      "[Parallel(n_jobs=-1)]: Done 593 tasks      | elapsed: 212.3min\n",
      "[Parallel(n_jobs=-1)]: Done 628 tasks      | elapsed: 246.3min\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed: 274.7min finished\n"
     ]
    }
   ],
   "source": [
    "sim_synthetic = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_one_synthetic)(unique_name, model_type, extract_seed(unique_name)) \n",
    "    for unique_name in unique_names\n",
    "    for model_type in model_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
