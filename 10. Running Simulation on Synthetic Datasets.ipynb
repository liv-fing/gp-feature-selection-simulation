{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Running Simulation on Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from gp_feature_select import GPFeatureSelect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing GPFeatureSelect with a simple dataset\n",
    "\n",
    "X = pd.read_csv('Simulation Datasets/N11000_AP10_noise0.1_seed0/Size50/Rep1.csv').drop(columns='y') \n",
    "y = pd.read_csv('Simulation Datasets/N11000_AP10_noise0.1_seed0/Size50/Rep1.csv')['y']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mod = GPFeatureSelect(model_type = 'std')\n",
    "mod.fit(Xtrain, ytrain)\n",
    "\n",
    "meta_path = '/Users/liviafingerson/Documents/GitHub/IEMS399-GP/Simulation Datasets/N11000_AP10_noise0.1_seed0/N11000_AP10_noise0.1_seed0_meta.json'\n",
    "with open(meta_path, 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    beta_true = np.array(meta['beta'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mod.get_metrics(Xtrain, ytrain, Xtest, ytest, beta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_synthetic(unique_name, size, num_rep, model_type, seed):\n",
    "\n",
    "    meta_path = f'Simulation Datasets/{unique_name}/{unique_name}_meta.json'\n",
    "    test_path = f'Simulation Datasets/{unique_name}/{unique_name}_test.csv'\n",
    "\n",
    "    data_path = f'Simulation Datasets/{unique_name}/Size{size}/Rep{num_rep}.csv' \n",
    "\n",
    "    results_path = f'Simulation Datasets/{unique_name}/Size{size}/Rep{num_rep}_{model_type}results.json'\n",
    "\n",
    "    #if os.path.exists(results_path):\n",
    "    #    #print(f\"Results file {results_path} already exists, skipping computation.\")\n",
    "    #    return\n",
    "\n",
    "    print(f\"Processing {unique_name}, Size: {size}, Rep: {num_rep}, Model: {model_type}, Seed: {seed}\")\n",
    "\n",
    "    X = pd.read_csv(data_path).drop(columns='y') \n",
    "    y = pd.read_csv(data_path)['y']\n",
    "\n",
    "    Xtest = pd.read_csv(test_path).drop(columns='y')\n",
    "    ytest = pd.read_csv(test_path)['y']\n",
    "\n",
    "    # open meta data and true beta values\n",
    "    with open(meta_path, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    beta_true = np.array(meta['beta'])\n",
    "                \n",
    "    mod = GPFeatureSelect(model_type=model_type)\n",
    "    #print('Fitting model')\n",
    "    mod.fit(X, y)\n",
    "    #print('Getting metrics')\n",
    "    results = mod.get_metrics(X, y, Xtest, ytest, beta_true=beta_true)\n",
    "\n",
    "    for k, v in results.items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            results[k] = v.tolist()\n",
    "    #print('Saving results')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "def extract_seed(unique_name):\n",
    "    seed_str = unique_name.split('_')[-1]\n",
    "    return int(seed_str.replace('seed', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Seed from N11000_AP20_noise1.0_seed5: 5\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'Simulation Datasets'\n",
    "unique_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "print(f'Extracting Seed from {unique_names[0]}: {extract_seed(unique_names[0])}')\n",
    "\n",
    "model_types = ['std', 'ard'] #['l1_gp', 'std', 'ard', 'lasso_std', 'lasso_ard', 'l1_gp']\n",
    "\n",
    "sizes = [1000] #[50, 100, 500, 1000]\n",
    "num_reps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 4, Model: ard, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 1, Model: ard, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 3, Model: std, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 5, Model: ard, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 2, Model: ard, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 5, Model: std, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 3, Model: ard, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 4, Model: std, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 2, Model: std, Seed: 5\n",
      "Processing N11000_AP20_noise1.0_seed5, Size: 1000, Rep: 1, Model: std, Seed: 5\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 1, Model: std, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 1, Model: ard, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 2, Model: std, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 2, Model: ard, Seed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 3, Model: std, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 3, Model: ard, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 4, Model: std, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 4, Model: ard, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 5, Model: std, Seed: 1\n",
      "Processing N11000_AP10_noise0.5_seed1, Size: 1000, Rep: 5, Model: ard, Seed: 1\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 1, Model: std, Seed: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   57.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 1, Model: ard, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 2, Model: std, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 2, Model: ard, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 3, Model: std, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 3, Model: ard, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 4, Model: std, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 4, Model: ard, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 5, Model: std, Seed: 3\n",
      "Processing N11000_AP20_noise0.1_seed3, Size: 1000, Rep: 5, Model: ard, Seed: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 1, Model: std, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 1, Model: ard, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 2, Model: std, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 2, Model: ard, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 3, Model: std, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 3, Model: ard, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 4, Model: std, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 4, Model: ard, Seed: 0\n",
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 5, Model: std, Seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP10_noise0.1_seed0, Size: 1000, Rep: 5, Model: ard, Seed: 0\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 1, Model: std, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 1, Model: ard, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 2, Model: std, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 2, Model: ard, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 3, Model: std, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 3, Model: ard, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 4, Model: std, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 4, Model: ard, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 5, Model: std, Seed: 4\n",
      "Processing N11000_AP20_noise0.5_seed4, Size: 1000, Rep: 5, Model: ard, Seed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 1, Model: std, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 1, Model: ard, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 2, Model: std, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 2, Model: ard, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 3, Model: std, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 3, Model: ard, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 4, Model: std, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 4, Model: ard, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 5, Model: std, Seed: 8\n",
      "Processing N11000_AP50_noise1.0_seed8, Size: 1000, Rep: 5, Model: ard, Seed: 8\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 1, Model: std, Seed: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 1, Model: ard, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 2, Model: std, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 2, Model: ard, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 3, Model: std, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 3, Model: ard, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 4, Model: std, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 4, Model: ard, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 5, Model: std, Seed: 2\n",
      "Processing N11000_AP10_noise1.0_seed2, Size: 1000, Rep: 5, Model: ard, Seed: 2\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 1, Model: std, Seed: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 1, Model: ard, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 2, Model: ard, Seed: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 3, Model: std, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 2, Model: std, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 3, Model: ard, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 4, Model: std, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 4, Model: ard, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 5, Model: std, Seed: 7\n",
      "Processing N11000_AP50_noise0.5_seed7, Size: 1000, Rep: 5, Model: ard, Seed: 7\n"
     ]
    }
   ],
   "source": [
    "sim_synthetic = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_one_synthetic)(unique_name, size, num_rep, model_type, extract_seed(unique_name)) \n",
    "    for unique_name in unique_names\n",
    "    for size in sizes\n",
    "    for num_rep in range(1, num_reps + 1)\n",
    "    for model_type in model_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
